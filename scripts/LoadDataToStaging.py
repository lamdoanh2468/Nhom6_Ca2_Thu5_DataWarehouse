import os
import glob
import shutil
import pandas as pd
from db_connector import get_connection, log_etl

def run_staging_process():
    process_name = "Staging_Load_Process"
    log_etl(process_name, "Running", "B·∫Øt ƒë·∫ßu qu√©t file CSV ƒë·ªÉ n·∫°p Staging...")

    # 1. Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c
    # L·∫•y th∆∞ m·ª•c cha c·ªßa scripts (D:/LaptopDW)
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    raw_path = os.path.join(base_dir, 'data', 'raw')
    processed_path = os.path.join(base_dir, 'data', 'processed')

    # T·∫°o th∆∞ m·ª•c processed n·∫øu ch∆∞a c√≥ (ƒë·ªÉ l∆∞u b·∫£n sao file sau khi xong)
    if not os.path.exists(processed_path):
        os.makedirs(processed_path)

    # 2. T√¨m t·∫•t c·∫£ file .csv trong th∆∞ m·ª•c data/raw
    csv_files = glob.glob(os.path.join(raw_path, "*.csv"))

    if not csv_files:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu m·ªõi n√†o trong 'data/raw'.")
        # Ghi log Success ƒë·ªÉ b√°o h·ªá th·ªëng bi·∫øt l√† ch·∫°y xong (d√π kh√¥ng c√≥ vi·ªác g√¨ l√†m)
        log_etl(process_name, "Success", "Kh√¥ng c√≥ file m·ªõi ƒë·ªÉ n·∫°p.", 0)
        return

    # 3. K·∫øt n·ªëi Database Staging
    conn = get_connection('staging')
    if not conn:
        print("‚ùå Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c database Staging.")
        return
    
    cursor = conn.cursor()
    total_files = 0
    total_rows = 0

    try:
        # 4. L√†m s·∫°ch b·∫£ng Staging (Full Load Strategy)
        # V√¨ Staging ch·ªâ l√† v√πng ƒë·ªám ch·ª©a d·ªØ li·ªáu m·ªõi nh·∫•t, n√™n x√≥a c≈© n·∫°p m·ªõi.
        print("üßπ ƒêang l√†m s·∫°ch b·∫£ng stg_laptops...")
        cursor.execute("TRUNCATE TABLE stg_laptops")
        
        # 5. Duy·ªát qua t·ª´ng file CSV t√¨m ƒë∆∞·ª£c
        for file_path in csv_files:
            file_name = os.path.basename(file_path)
            print(f"üìÇ ƒêang x·ª≠ l√Ω file: {file_name}")

            try:
                # ƒê·ªçc file CSV v√†o DataFrame
                df = pd.read_csv(file_path)
                
                # Ki·ªÉm tra n·∫øu file r·ªóng
                if df.empty:
                    print(f"   ‚ö†Ô∏è File {file_name} r·ªóng, b·ªè qua.")
                    # Copy sang processed ƒë·ªÉ l∆∞u v·∫øt thay v√¨ move
                    shutil.copy(file_path, os.path.join(processed_path, file_name))
                    continue

                # Chu·∫©n b·ªã c√¢u l·ªánh Insert
                # L∆∞u √Ω: S·ªë l∆∞·ª£ng %s ph·∫£i kh·ªõp v·ªõi s·ªë c·ªôt trong VALUES
                sql = """
                    INSERT INTO stg_laptops 
                    (Name, Price, links_href, CpuType, Ram, Storage, Display, GPU, OSystem, Battery, Resolution, ScrapeTimestamp) 
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                """
                
                # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu DataFrame th√†nh List of Tuples ƒë·ªÉ n·∫°p batch
                val_list = []
                for _, row in df.iterrows():
                    # S·ª≠ d·ª•ng .get('', '') ƒë·ªÉ tr√°nh l·ªói n·∫øu file CSV thi·∫øu c·ªôt
                    # √âp ki·ªÉu str() ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng l·ªói d·ªØ li·ªáu
                    val_list.append((
                        str(row.get('Name', '')), 
                        str(row.get('Price', '0')), 
                        str(row.get('links_href', '')), 
                        str(row.get('CpuType', '')), 
                        str(row.get('Ram', '')), 
                        str(row.get('Storage', '')), 
                        str(row.get('Display', '')), 
                        str(row.get('GPU', '')), 
                        str(row.get('OSystem', '')),
                        str(row.get('Battery', '')), 
                        str(row.get('Resolution', ''))
                    ))

                # Th·ª±c thi n·∫°p h√†ng lo·∫°t (Bulk Insert) -> T·ªëc ƒë·ªô cao
                cursor.executemany(sql, val_list)
                
                rows_in_file = len(val_list)
                total_rows += rows_in_file
                total_files += 1
                
                print(f"   ‚úÖ ƒê√£ n·∫°p {rows_in_file} d√≤ng.")

                # 6. Copy file ƒë√£ n·∫°p xong sang th∆∞ m·ª•c 'processed'
                # S·ª¨A ƒê·ªîI: D√πng shutil.copy thay v√¨ shutil.move ƒë·ªÉ gi·ªØ nguy√™n file g·ªëc ·ªü data/raw
                shutil.copy(file_path, os.path.join(processed_path, file_name))
                print(f"   üì¶ ƒê√£ SAO CH√âP file v√†o 'data/processed' (file g·ªëc v·∫´n c√≤n).")

            except Exception as e_file:
                print(f"   ‚ùå L·ªói khi x·ª≠ l√Ω file {file_name}: {e_file}")
                # N·∫øu l·ªói file n√†y, log l·∫°i v√† ti·∫øp t·ª•c file kh√°c (kh√¥ng d·ª´ng ch∆∞∆°ng tr√¨nh)
                log_etl(process_name, "Warning", f"L·ªói file {file_name}: {str(e_file)}")

        # 7. Commit giao d·ªãch (L∆∞u vƒ©nh vi·ªÖn v√†o DB)
        conn.commit()
        
        msg = f"Ho√†n t·∫•t Staging. X·ª≠ l√Ω {total_files} file, n·∫°p t·ªïng c·ªông {total_rows} d√≤ng."
        print(f"üéâ {msg}")
        log_etl(process_name, "Success", msg, total_rows)

    except Exception as e:
        conn.rollback() # Ho√†n t√°c n·∫øu c√≥ l·ªói nghi√™m tr·ªçng
        err_msg = f"L·ªói h·ªá th·ªëng Staging: {str(e)}"
        print(f"üî• {err_msg}")
        log_etl(process_name, "Failed", err_msg)
        
    finally:
        cursor.close()
        conn.close()

if __name__ == "__main__":
    run_staging_process()